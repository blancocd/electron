#!/bin/bash
# Admin stuff
# Job's name will be KHARMA and can be checked later with squeue -u yourusername
#SBATCH -J KHARMA
# The time allocated for the job, you may want to increase this
#SBATCH -t 24:00:00
# Number of nodes that are to be used
#SBATCH -N 1
# The output will be written to out-numberOfJob.txt
#SBATCH -o "out-%j.txt"
# Account is GPU
#SBATCH --account=bbhr-delta-gpu

# Nodes we want, you may recognize these as GPU models
#SBATCH --partition=gpuA100x4
#SBATCH --gpus-per-node=4
#SBATCH --tasks-per-node=4
# OR
##SBATCH --partition=gpuA100x8
##SBATCH --gpus-per-node=8
##SBATCH --tasks-per-node=8

# Node options
# 8-way nodes are 2 sockets, so this is constant
#SBATCH --cpus-per-task=16
# ALWAYS reserve full nodes to mitigate memory leaks
#SBATCH --exclusive
#SBATCH --mem=0

# NCSA Delta run script

# OpenMP directives: use all available threads
export OMP_PROC_BIND=spread
export OMP_PLACES=threads

# If you see weird GPU race conditions, setting this
# to 1 *might* fix them. Maybe.
export CUDA_LAUNCH_BLOCKING=0
# Kokkos can be forced to a particular device:
#export KOKKOS_DEVICE_ID=0

# Choose the kharma from compiled options in order of preference
KHARMA_DIR="$HOME/kharma"

# Optionally use the Kokkos tools to profile kernels
#export KOKKOS_PROFILE_LIBRARY=$KHARMA_DIR/../kokkos-tools/kp_kernel_timer.so
#export KOKKOS_PROFILE_LIBRARY=$KHARMA_DIR/../kokkos-tools/kp_nvprof_cnnector.so

# Load any defaults/modules from the machine file
HOST=$(hostname -f)
ARGS=$(cat $KHARMA_DIR/make_args)
for machine in $KHARMA_DIR/machines/*.sh
do
  source $machine
done

export KOKKOS_NUM_DEVICES=$SLURM_NTASKS_PER_NODE

# Run with srun, I am not sure why there is a second time here. But I am almost 
# sure that this one is followed rather than the one before.
srun $KHARMA_DIR/kharma.cuda -t 23:50:00 -d dumps "$@"
